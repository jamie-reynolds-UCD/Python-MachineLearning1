{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGaussianNB(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "        self.__mean_std_dict = {}\n",
    "        \n",
    "        # find each unique class and for each of these classes\n",
    "        classes = np.unique(y)\n",
    "        for c in classes:\n",
    "            # get all indicies for this class\n",
    "            indices = np.where(y==c)\n",
    "            \n",
    "            # for each column of this class, find the mean and std\n",
    "            self.__mean_std_dict[c] = {'prior_prob':(len(indices[0])/len(X))}\n",
    "            \n",
    "            for i in range(len(X[0])):\n",
    "                self.__mean_std_dict[c][i] = {'mean':(X[indices,i].mean()), 'std':(X[indices,i].std())}\n",
    "            \n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \n",
    "        self.X = X\n",
    "        \n",
    "        predictions = np.empty([0,len(X)])\n",
    "        \n",
    "        def conditionalProba(val, mean, stdev):\n",
    "            '''\n",
    "            Function that takes a value, a mean value and a standard deviation value.\n",
    "            It inputs these into a formula supplied in the assignment question and outputs the\n",
    "            resulting conditional probability for each value.\n",
    "            '''\n",
    "            \n",
    "            if stdev == 0:\n",
    "                if val == mean:\n",
    "                    return 1\n",
    "                else:\n",
    "                    return 0\n",
    "                \n",
    "            probability = (1/(2*np.pi*(stdev**2))**0.5) * np.exp(-((val-mean)**2)/(2*(stdev**2)))\n",
    "            return probability\n",
    "        \n",
    "        classes = self.__mean_std_dict.keys()\n",
    "        \n",
    "        # go through each row of the training data\n",
    "        # for each row\n",
    "            # make a dictionary for probabilities for each possible class\n",
    "            \n",
    "        for i in range(len(X)):\n",
    "            probDict = {}\n",
    "            currentRow = X[i]\n",
    "            \n",
    "            # for each possible class\n",
    "                # add a list that includes the current class's prior probability to current\n",
    "                # class key in the dictionary\n",
    "            for c in classes:\n",
    "                probDict[c] = [self.__mean_std_dict[c]['prior_prob']]\n",
    "                \n",
    "                # for each column value in the current row\n",
    "                    # find the mean and std for this column and class in the mean_std_dict\n",
    "                    # plug the current column value, the mean for this column and the std\n",
    "                    # for this column into the conditionalProba() function\n",
    "                    # append the value returned from this to the current class key in the\n",
    "                    # probability dictionary\n",
    "                for j in range(len(currentRow)):\n",
    "                    val = currentRow[j]\n",
    "                    mean = self.__mean_std_dict[c][j]['mean']\n",
    "                    std = self.__mean_std_dict[c][j]['std']\n",
    "                    probDict[c].append(conditionalProba(val, mean, std))\n",
    "                    \n",
    "                # when the conditional probabilities for each column have been added to the dictionary\n",
    "                # get the product of each of these values and assign it to the probability dictionary\n",
    "                # for the current class\n",
    "                probDict[c] = np.prod(probDict[c])\n",
    "                \n",
    "            # normalise the probabilities for each class\n",
    "            total = sum(probDict.values())\n",
    "            for k in probDict.keys():\n",
    "                val = probDict[k]\n",
    "                probDict[k] = val/total\n",
    "                \n",
    "            # get the class name with the highest normalised probability from the dictionary values\n",
    "            # append the class name to the list of predictions\n",
    "            index = list(probDict.values()).index(max(probDict.values()))\n",
    "            predictions = np.append(predictions, list(probDict.keys())[index])\n",
    "            \n",
    "        # return the list of predictions\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process:\n",
    "- I will be creating models for 3 datasets: penguins_af.csv, diabetes.csv and glassV2.csv, using the MyGaussianNB class defined above.\n",
    "- As each of the datasets are small, I will evaluate each model's performance using 5-fold cross-validation. This will give a more robust evaluation of each model's performance.\n",
    "- I will compare the models created by MyGaussianNB to models created with scikit-learn's GaussianNB class across the following scores:\n",
    "    - accuracy\n",
    "    - confusion matrices\n",
    "    - precision\n",
    "    - recall\n",
    "    - f1 score\n",
    "    - balanced accuracy score (as each of the datasets is skewed towards one or more results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read penguins data and format it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = pd.read_csv('penguins_af.csv', index_col=0)\n",
    "penguins.reset_index(drop=True, inplace=True)\n",
    "y_penguins = penguins.pop('species')\n",
    "penguins = pd.get_dummies(penguins)\n",
    "penguins = penguins.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This leaves us with a numpy array for the penguins data and a pandas series for the classes\n",
    "\n",
    "### Create model objects for the penguins data using MyGaussianNB and GaussianNB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "myPenguin = MyGaussianNB()\n",
    "gaussianPenguin = GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read diabetes data and format it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv('diabetes.csv', index_col=0)\n",
    "diabetes.reset_index(drop=True, inplace=True)\n",
    "y_diabetes = diabetes.pop('neg_pos')\n",
    "diabetes = pd.get_dummies(diabetes)\n",
    "diabetes = diabetes.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model objects for the diabetes data using MyGaussianNB and GaussianNB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDiabetes = MyGaussianNB()\n",
    "gaussianDiabetes = GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read glassV2 data and format it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glass = pd.read_csv('glassV2.csv', index_col=0)\n",
    "glass.reset_index(drop=True, inplace=True)\n",
    "y_glass = glass.pop('Type')\n",
    "glass = pd.get_dummies(glass)\n",
    "glass = glass.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model objects for the glass data using MyGaussianNB and GaussianNB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myGlass = MyGaussianNB()\n",
    "gaussianGlass = GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each dataset, I will use 5-fold cross validation to evaluate each model in terms of its accuracy; confusion rate; precision and recall rates; and the balanced accuracy and balanced error rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# penguins\n",
    "data = \"penguins\"\n",
    "models = [myPenguin, gaussianPenguin]\n",
    "X = penguins\n",
    "y = y_penguins\n",
    "\n",
    "print(f'Classes are {y.unique()}')\n",
    "\n",
    "for m in models:\n",
    "    print(\"------------------------------------\")\n",
    "    print(type(m).__name__, data, \"data:\")\n",
    "    print(\"------------------------------------\")\n",
    "    accuracy = cross_val_score(m, X, y, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    print(f\"accuracy: {accuracy.mean()}\")\n",
    "    \n",
    "    y_pred = cross_val_predict(m, X, y, cv=5)\n",
    "    conf_mat = confusion_matrix(y, y_pred)\n",
    "    print(f\"confusion matrix: \\n{conf_mat}\")\n",
    "    \n",
    "    precision = precision_score(y, y_pred, average='weighted')\n",
    "    print(f\"precision score: {precision}\")\n",
    "    \n",
    "    recall = recall_score(y, y_pred, average='weighted')\n",
    "    print(f\"recall score: {recall}\")\n",
    "    \n",
    "    f1 = f1_score(y, y_pred, average='weighted')\n",
    "    print(f\"f1 score: {f1}\")\n",
    "    \n",
    "    bas = balanced_accuracy_score(y, y_pred)\n",
    "    print(f\"balanced accuracy score: {bas}\")\n",
    "    print(\"------------------------------------\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## penguins data conclusions:\n",
    "- As we can see, the MyGaussianNB classifier outperforms scikit-learn's GaussianNB classifier in every metric.\n",
    "- From the confusion matrix we can see that difference in performance mainly occurs in the prediction of the second class: Gentoo. While the GaussianNB class predicts 93 actual Adelie classes, and 52 Gentoo classes that are actually Adelie classes, the MyGaussianNB classifier predicts 142 actual Adelie classes, and just 4 Gentoo classes that are actually Adelie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diabetes\n",
    "data = \"diabetes\"\n",
    "models = [myDiabetes, gaussianDiabetes]\n",
    "X = diabetes\n",
    "y = y_diabetes\n",
    "\n",
    "print(f'Classes are {y.unique()}')\n",
    "\n",
    "for m in models:\n",
    "    print(\"------------------------------------\")\n",
    "    print(type(m).__name__, data, \"data:\")\n",
    "    print(\"------------------------------------\")\n",
    "    accuracy = cross_val_score(m, X, y, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    print(f\"accuracy: {accuracy.mean()}\")\n",
    "    \n",
    "    y_pred = cross_val_predict(m, X, y, cv=5)\n",
    "    conf_mat = confusion_matrix(y, y_pred)\n",
    "    print(f\"confusion matrix: \\n{conf_mat}\")\n",
    "    \n",
    "    precision = precision_score(y, y_pred, average='weighted')\n",
    "    print(f\"precision score: {precision}\")\n",
    "    \n",
    "    recall = recall_score(y, y_pred, average='weighted')\n",
    "    print(f\"recall score: {recall}\")\n",
    "    \n",
    "    f1 = f1_score(y, y_pred, average='weighted')\n",
    "    print(f\"f1 score: {f1}\")\n",
    "    \n",
    "    bas = balanced_accuracy_score(y, y_pred)\n",
    "    print(f\"balanced accuracy score: {bas}\")\n",
    "    print(\"------------------------------------\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## diabetes data conclusions:\n",
    "- As we can see, the predictions for both of the classifiers for the diabetes data is identical. This is noteworthy, as this only data has two possible classes. I will try the classifiers on another dataset with 2 possible classes to see if the results are the same in that case. \n",
    "\n",
    "#### Below, I took the penguins dataset with only 2 of the classes – Adelie and Gentoo – and ran the corss validation metrics on them to see the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = pd.read_csv('penguins_af.csv', index_col=0)\n",
    "penguins.reset_index(drop=True, inplace=True)\n",
    "y_penguins = penguins.pop('species')\n",
    "penguins = pd.get_dummies(penguins)\n",
    "penguins = penguins.to_numpy()\n",
    "y_penguins.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_penguins2 = pd.Series(list(y_penguins[y_penguins=='Adelie']) + list(y_penguins[y_penguins=='Gentoo']))\n",
    "index = list(y_penguins[y_penguins=='Adelie'].index) + list(y_penguins[y_penguins=='Gentoo'].index)\n",
    "penguins2 = penguins[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myPenguin2 = MyGaussianNB()\n",
    "gaussianPenguin2 = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# penguins2\n",
    "data = \"penguins2\"\n",
    "models = [myPenguin2, gaussianPenguin2]\n",
    "X = penguins2\n",
    "y = y_penguins2\n",
    "\n",
    "print(f'Classes are {y.unique()}')\n",
    "\n",
    "for m in models:\n",
    "    print(\"------------------------------------\")\n",
    "    print(type(m).__name__, data, \"data:\")\n",
    "    print(\"------------------------------------\")\n",
    "    accuracy = cross_val_score(m, X, y, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    print(f\"accuracy: {accuracy.mean()}\")\n",
    "    \n",
    "    y_pred = cross_val_predict(m, X, y, cv=5)\n",
    "    conf_mat = confusion_matrix(y, y_pred)\n",
    "    print(f\"confusion matrix: \\n{conf_mat}\")\n",
    "    \n",
    "    precision = precision_score(y, y_pred, average='weighted')\n",
    "    print(f\"precision score: {precision}\")\n",
    "    \n",
    "    recall = recall_score(y, y_pred, average='weighted')\n",
    "    print(f\"recall score: {recall}\")\n",
    "    \n",
    "    f1 = f1_score(y, y_pred, average='weighted')\n",
    "    print(f\"f1 score: {f1}\")\n",
    "    \n",
    "    bas = balanced_accuracy_score(y, y_pred)\n",
    "    print(f\"balanced accuracy score: {bas}\")\n",
    "    print(\"------------------------------------\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## penguins2 data conclusions:\n",
    "- As we can see, both classifiers preformed very well on the penguins data liited to 2 outcomes\n",
    "- The MyGaussianNB class performed slightly better – with the GaussianNB class predicting 1 Gentoo class that was actually an Adelie class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glass\n",
    "data = \"glass\"\n",
    "models = [myGlass, gaussianGlass]\n",
    "X = glass\n",
    "y = y_glass\n",
    "\n",
    "print(f'Classes are {y.unique()}')\n",
    "\n",
    "for m in models:\n",
    "    print(\"------------------------------------\")\n",
    "    print(type(m).__name__, data, \"data:\")\n",
    "    print(\"------------------------------------\")\n",
    "    accuracy = cross_val_score(m, X, y, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    print(f\"accuracy: {accuracy.mean()}\")\n",
    "    \n",
    "    y_pred = cross_val_predict(m, X, y, cv=5)\n",
    "    conf_mat = confusion_matrix(y, y_pred)\n",
    "    print(f\"confusion matrix: \\n{conf_mat}\")\n",
    "    \n",
    "    precision = precision_score(y, y_pred, average='weighted')\n",
    "    print(f\"precision score: {precision}\")\n",
    "    \n",
    "    recall = recall_score(y, y_pred, average='weighted')\n",
    "    print(f\"recall score: {recall}\")\n",
    "    \n",
    "    f1 = f1_score(y, y_pred, average='weighted')\n",
    "    print(f\"f1 score: {f1}\")\n",
    "    \n",
    "    bas = balanced_accuracy_score(y, y_pred)\n",
    "    print(f\"balanced accuracy score: {bas}\")\n",
    "    print(\"------------------------------------\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glass data conclusions:\n",
    "- As we can see, the MyGaussianNB class performed better across all metrics. \n",
    "- This can be seen particularly in the predictions of the '1' class: the MyGaussianNB class predicted 47 actual classes, whereas the GaussianNB class predicted the 35 of the actual '1' class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final conclusions:\n",
    "- The MyGaussianNB class performed notably better than the GaussianNB class in all multiclass datasets. In binary class datasets, the results were much closer: identical in the diabetes dataset and 1 prediction in the difference (in favour of the MyGaussianNB class) for the penguins dataset with 2 outcomes.\n",
    "- This leads to my over all conclusion that the MyGaussianNB classifier is a more accurate classifier than the scikit-learn GaussianNB classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
